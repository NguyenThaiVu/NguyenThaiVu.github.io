<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-11-15T20:06:20-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Data Science Project</title><subtitle>Data is the new oil.</subtitle><entry><title type="html">Milestone 2</title><link href="http://localhost:4000/data/science/project/2023/11/14/milestone-2.html" rel="alternate" type="text/html" title="Milestone 2" /><published>2023-11-14T14:25:05-05:00</published><updated>2023-11-14T14:25:05-05:00</updated><id>http://localhost:4000/data/science/project/2023/11/14/milestone-2</id><content type="html" xml:base="http://localhost:4000/data/science/project/2023/11/14/milestone-2.html"><![CDATA[<h1 id="table-of-content">Table of content:</h1>
<ul>
  <li><a href="#1-feature-engineering-1">1. Feature Engineering 1</a></li>
  <li><a href="#2-baseline-model">2. Baseline Model</a>
    <ul>
      <li><a href="#21-unveiling-the-accuracy-paradox">2.1. Unveiling the Accuracy Paradox</a></li>
      <li><a href="#22-evaluating-baselines">2.2. Evaluating Baselines</a></li>
    </ul>
  </li>
  <li><a href="#3-feature-engineering-2">3. Feature Engineering 2</a>
    <ul>
      <li><a href="#31-add-features">3.1. Add Features</a></li>
      <li><a href="#32-add-json-file">3.2. Add Json File</a></li>
    </ul>
  </li>
  <li><a href="#4-advanced-model">4. Advanced Model</a></li>
  <li><a href="#5-best-shot-model">5. Best Shot Model</a>
    <ul>
      <li><a href="#51-data-pre-processing">5.1. Data Pre-processing</a>
        <ul>
          <li><a href="#511-add-feature">5.1.1. Add Feature</a></li>
          <li><a href="#512-feature-selection---correlation">5.1.2. Feature Selection - Correlation</a></li>
          <li><a href="#513-feature-selection---mutual-information">5.1.3. Feature Selection - Mutual Information</a></li>
          <li><a href="#514-balance-dataset">5.1.4. Balance Dataset</a></li>
        </ul>
      </li>
      <li><a href="#52-machine-learning-model-grid-search">5.2. Machine Learning Model Grid Search</a></li>
      <li><a href="#53-log-the-models-to-the-experiments-on-cometml">5.3. Log the Models to the Experiments on Comet.ml</a></li>
    </ul>
  </li>
  <li><a href="#6-evaluation">6. Evaluation</a>
    <ul>
      <li><a href="#61-evaluate-on-regular-season">6.1. Evaluate on Regular Season</a></li>
      <li><a href="#62-evaluate-on-playoff-game">6.2. Evaluate on Playoff Game</a></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="1-feature-engineering-1">1. Feature Engineering 1</h2>

<hr />
<h2 id="2-baseline-model">2. Baseline Model</h2>

<p>In the provided notebook, we implemented baseline models for predicting goal outcomes in hockey games. The notebook begins by importing necessary libraries, setting up directories for data, models, and figures, and initializing Comet experiments for experiment tracking. It then loads the dataset, preprocesses it by selecting desired features, and splits it into training and validation sets. Logistic regression models are trained separately for shot distance, shot angle, and a combination of both features. The notebook includes visualizations such as confusion matrices, ROC curves, goal rate, cumulative percentage of goal, and calibration curves for each model. Random predictions are also generated as a baseline. The notebook concludes with logging relevant metrics and saving the trained models, confusion matrices, and metrics on Comet for further analysis. The models and experiments are tagged appropriately, indicating their baseline nature and the features used in training.</p>

<h3 id="21-unveiling-the-accuracy-paradox">2.1. Unveiling the Accuracy Paradox</h3>

<p>The histogram of the labels in the training dataset:
<img src="/Images/baseline/hist.png" alt="" /></p>

<p>The evaluation results indicate a high accuracy of 91% on the validation set, but upon closer inspection of the precision, recall, and f1-score for label 1 (goal), it becomes apparent that the model is unable to correctly predict instances of this class, yielding zeros in these metrics.</p>

<p>The issue arises from the significant class imbalance in the dataset, where label 0 (non-goal) vastly outnumbers label 1. With 276,782 samples for label 0 and only 29,032 samples for label 1, the model might be biased towards predicting the majority class, achieving high accuracy due to the dominance of label 0 in the dataset. However, this high accuracy is misleading, as the model struggles to capture the minority class (label 1).</p>

<h3 id="22-evaluating-baselines">2.2. Evaluating Baselines</h3>

<p><img src="/Images/baseline/baseline-evaluation.png" alt="" /></p>

<p>As we can see, the simplest baseline, random prediction, acts exactly the same as random models, having 50 percent area under the curve in the ROC plot and steady in goal rate and calibration plots.</p>

<p>On the other hand, we have noticed slight improvement from the angle model to the distance model and then from there to the model using a combination of them showing that as we increase the number of features, we encounter better performance in evaluation.</p>

<p>We add the experiment to the comet. You can access to those experiment by the following links:</p>

<ul>
  <li>
    <p>Baseline Model - Distance: <a href="https://www.comet.com/ift6758-b09-project/ift6758-project-milestone2/fd6f683bf9324bc4aafe732516e9ed38">here</a></p>
  </li>
  <li>
    <p>Baseline Model - Angle: <a href="https://www.comet.com/ift6758-b09-project/ift6758-project-milestone2/066eb71923294143887d23136514beb5">here</a></p>
  </li>
  <li>
    <p>Baseline Model - Distance + Angle: <a href="https://www.comet.com/ift6758-b09-project/ift6758-project-milestone2/90775941400f48689503c7bacdc0ff09">here</a></p>
  </li>
</ul>

<hr />
<h2 id="3-feature-engineering-2">3. Feature Engineering 2</h2>

<h3 id="31-add-features">3.1. Add Features</h3>

<p>We added the features from the list below</p>

<table>
  <thead>
    <tr>
      <th>Feature Name</th>
      <th>Explanation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>game_second</td>
      <td>Time (in seconds) of each event relative to the start of the entire game</td>
    </tr>
    <tr>
      <td>last_event_type</td>
      <td>Type of the last event.</td>
    </tr>
    <tr>
      <td>coor_x_last_event</td>
      <td>X-coordinate of the last event.</td>
    </tr>
    <tr>
      <td>coor_y_last_event</td>
      <td>Y-coordinate of the last event.</td>
    </tr>
    <tr>
      <td>time_last_event</td>
      <td>Time elapsed since the last event (seconds).</td>
    </tr>
    <tr>
      <td>distance_last_event</td>
      <td>Distance from the last event.</td>
    </tr>
    <tr>
      <td>is_rebound</td>
      <td>True if the last event was a rebound, otherwise False.</td>
    </tr>
    <tr>
      <td>Change in shot angle</td>
      <td>Angle change in the shot, only applicable for rebounds.</td>
    </tr>
    <tr>
      <td>Speed</td>
      <td>Defined as distance from the previous event divided by time.</td>
    </tr>
    <tr>
      <td>power_play_time <strong>(bonus)</strong></td>
      <td>Time elapsed since the start of the power play (seconds).</td>
    </tr>
    <tr>
      <td>n_friend        <strong>(bonus)</strong></td>
      <td>Number of friendly non-goalie skaters on the ice.</td>
    </tr>
    <tr>
      <td>n_oppose        <strong>(bonus)</strong></td>
      <td>Number of opposing non-goalie skaters on the ice.</td>
    </tr>
  </tbody>
</table>

<p>After adding the features, we processed the data:</p>
<ul>
  <li>First we split the data into a training set and a test set (the function <code class="language-plaintext highlighter-rouge">split_train_test()</code> was used here), and the subsequent processing of the data will be different depending on the model chosen.</li>
  <li>Then we removed features that were not relevant to the modeling (the function <code class="language-plaintext highlighter-rouge">remove_extra_features()</code> was used) and added a new feature <code class="language-plaintext highlighter-rouge">game_second</code>.</li>
  <li>Finally we uploaded <code class="language-plaintext highlighter-rouge">train.csv</code>, <code class="language-plaintext highlighter-rouge">test_regular.csv</code>, <code class="language-plaintext highlighter-rouge">test_playoff.csv</code> to comet artifact.
You can download the dataset by the link <a href="https://www.comet.com/ift6758-b09-project/artifacts/dataset/4.0.2">here</a></li>
</ul>

<h3 id="32-add-json-file">3.2. Add Json File</h3>

<ul>
  <li>For this particular match, we wrote a separate py file <code class="language-plaintext highlighter-rouge">get_game.py</code> to run it, and the purpose of this file is to upload this match as a dataframe to comet.ml, named according to requirements(<code class="language-plaintext highlighter-rouge">wpg_v_wsh_2017021065.csv</code>)</li>
  <li>You can check the link: <a href="https://www.comet.com/ift6758-b09-project/ift6758-project-milestone2/c2985f085ae342bcbd8aa86aa9b3cb3c?experiment-tab=panels&amp;showOutliers=true&amp;smoothing=0&amp;xAxis=step">here</a></li>
</ul>

<hr />
<h2 id="4-advanced-model">4. Advanced Model</h2>

<hr />
<h2 id="5-best-shot-model">5. Best Shot Model</h2>

<h3 id="51-data-pre-processing">5.1. Data Pre-processing</h3>

<p>In this section, we will provide step-by-step our data pre-processing step, including: add feture, feature selection using correlation, feature selection using mutual information, and balance dataset.</p>

<h4 id="511-add-feature">5.1.1. Add Feature</h4>

<p>In this section, we will add the new feature called <code class="language-plaintext highlighter-rouge">attacking_zone_shot</code>. This feature indicates whether a shot took place within the opposing team’s attacking zone. We choose to analyze this feature based on the observation that the shot in the attacking zone has high chance to become a goal.</p>

<p>After analyzing, we’ve discerned that 94.5% of shots occurred within the attacking zone, while the remaining 5% happened outside this zone.</p>

<h4 id="512-feature-selection---correlation">5.1.2. Feature Selection - Correlation</h4>

<p>In this section, we will check the correlation value between pairs of features. If the correlation between two features is larger than the specific <code class="language-plaintext highlighter-rouge">threshold</code>, we will remove it. In this experiment, we set the threshold is 0.9.</p>

<p>After analyzing, the correlation between <code class="language-plaintext highlighter-rouge">period</code> and <code class="language-plaintext highlighter-rouge">game_second</code> is 0.94. Therefore, we remove features <code class="language-plaintext highlighter-rouge">['period']</code>.</p>

<h4 id="513-feature-selection---mutual-information">5.1.3. Feature Selection - Mutual Information</h4>

<p>On this section, we will use mutual information to identify the relationship between features and the target variable. The intuition behind this experiment is that higher mutual information indicates stronger predictive power.</p>

<p>After calculating the mutual information between each feature and target variable. We got the result
<img src="/Images/best_shot_model/mutual_information.jpg" alt="" /></p>

<p>According to the experiment, we will set the threshold below <strong>0.01</strong>. In other words, If the mutual information between each feature and target variable is smaller than 0.01, we will remove it.</p>

<p>After analyzing, we choose feature:
<code class="language-plaintext highlighter-rouge">['x-coordinate', 'y-coordinate', 'shot_distance', 'angle', 'isEmptyNet', 'n_friend', 'n_oppose', 'last_event_type', 'is_rebound', 'attacking_zone_shot']</code></p>

<h4 id="514-balance-dataset">5.1.4. Balance Dataset</h4>

<p>Because the distribution of label in the training set is imbalanced. We apply the over-sample to add more samples to the minority class.</p>

<h3 id="52-machine-learning-model-grid-search">5.2. Machine Learning Model Grid Search</h3>

<p>In this section, we run two type of models: decision tree and logistic regression with the preprocessed dataset. For the purpose of this experiment, we just run the simple grid search experiment and leave the complicated work later. The grid hyperparameter tuning on each model:</p>
<ul>
  <li>Grid search decision tree:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>param_grid_tree = {
  "tree__criterion": ['gini', 'entropy'],
  "tree__max_depth": [5, 10],
  "tree__min_samples_leaf": [5, 10]
}
</code></pre></div>    </div>
  </li>
  <li>Grid search logistic regression:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>param_grid_linear = {
  "linear_clf__penalty": ['l1', 'l2'],
  "linear_clf__C": [0.1, 0.01]
}
</code></pre></div>    </div>
    <p>We create four figures (ROC/AUC curve, goal rate vs probability percentile, cumulative proportion of goals vs probability percentile, and the reliability curve) to both ML model: decision tree and logistic regression.</p>
  </li>
</ul>

<p><img src="/Images/best_shot_model/best_shot_model.png" alt="" /></p>

<!-- #### i. The ROC/AUC curve
![](/Images/best_shot_model/roc.jpg)

#### ii. The goal rate vs probability percentile
![](/Images/best_shot_model/goal_rate.jpg)

#### iii. The cumulative proportion of goals vs probability percentile
![](/Images/best_shot_model/goal_cumulative_proportion.jpg)

#### iii. The reliability curve
![](/Images/best_shot_model/calibration.jpg) -->

<p>In addition, we also inspect the accuracy, f1 score, and the  ROC score on the validation set:</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Accuracy</th>
      <th>F1 score</th>
      <th>ROC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Decision Tree</td>
      <td>90.7%</td>
      <td>0.738</td>
      <td>0.74</td>
    </tr>
    <tr>
      <td>Logistic regression</td>
      <td>90.3%</td>
      <td>0.731</td>
      <td>0.73</td>
    </tr>
  </tbody>
</table>

<p>In summary, the decision tree is the best model we can build.</p>

<h3 id="53-log-the-models-to-the-experiments-on-cometml">5.3. Log the Models to the Experiments on Comet.ml</h3>

<p>We have include multiples experiment on the comet. In case you want to check the metrics of each experiment in a tabular format, you can check via this link: <a href="https://www.comet.com/ift6758-b09-project/ift6758-project-milestone2/view/new/experiments">here</a></p>

<p>We have add the trained decision tree into our Model Registry. You can download it with this link:</p>
<ul>
  <li>Decision tree model: <a href="https://www.comet.com/api/registry/model/item/download?modelItemId=ezJQ3TR5dmuvrVucdWsbKtYaR">here</a></li>
</ul>

<p>We also add the evaluation metrics to the Comet experiment. We add 3 metrics, including: Accuracy, ROC, and confusion matrix. 
You can access each individual experiment with the tag <code class="language-plaintext highlighter-rouge">best_shot_model</code> for more details.</p>

<hr />
<h2 id="6-evaluation">6. Evaluation</h2>

<p>Overall, our model perform well on both regular and playoff game, which mean that the generalization ability of our model is good.</p>

<h3 id="61-evaluate-on-regular-season">6.1. Evaluate on Regular Season</h3>

<p>On the logistic regression, the features combining distance and angle is better than each feature seperately.</p>

<p>The performance of the decision tree model is better than the baseline logistic regressions. One reason to explain that we apply more features and we balance the dataset.</p>

<p>Finally, the XGBoost model gets the highest ROC scores compared to other methods. One reason to explain for this scenarion is that the XGBoost is quite suitable for this type of tabular data. Moreover, our team perform the good feature selection process (part 5).</p>

<p>Our models perform with the approximately same ROC, goal rate, cumulative proportion, during the validation and testing set.</p>

<p>The ROC score of different models on the regular season compared to the validation set:</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Valivation set</th>
      <th>Test regular season</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Logistic regression (dist)</td>
      <td>0.69</td>
      <td>0.69</td>
    </tr>
    <tr>
      <td>Logistic regression (angle)</td>
      <td>0.57</td>
      <td>0.56</td>
    </tr>
    <tr>
      <td>Logistic regression (dist+angle)</td>
      <td>0.71</td>
      <td>0.71</td>
    </tr>
    <tr>
      <td>XGBoost</td>
      <td>0.77</td>
      <td>0.78</td>
    </tr>
    <tr>
      <td>Decision Tree</td>
      <td>0.74</td>
      <td>0.75</td>
    </tr>
  </tbody>
</table>

<p>The plot curve of ROC/AUC, Goal rate vs probability percentile, Cumulative proportion of goals vs probability percentile, and Reliability curve of the regular games.
<img src="/Images/evaluation/regular_evaluation.png" alt="" /></p>

<h3 id="62-evaluate-on-playoff-game">6.2. Evaluate on Playoff Game</h3>

<p>The ROC score of different models on the playoff game compared to the validation set:</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Valivation set</th>
      <th>Test playoff games</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Logistic regression (dist)</td>
      <td>0.69</td>
      <td>0.68</td>
    </tr>
    <tr>
      <td>Logistic regression (angle)</td>
      <td>0.57</td>
      <td>0.57</td>
    </tr>
    <tr>
      <td>Logistic regression (dist+angle)</td>
      <td>0.71</td>
      <td>0.70</td>
    </tr>
    <tr>
      <td>XGBoost</td>
      <td>0.77</td>
      <td>0.70</td>
    </tr>
    <tr>
      <td>Decision Tree</td>
      <td>0.74</td>
      <td>0.75</td>
    </tr>
  </tbody>
</table>

<p>There is slightly difference between ROC on the regular season and playoff games.</p>

<p>The XGBoost has the drop in ROC, compared to ROC in regular season. At that time, the generalization of the trained XGBoost has a little problem and need further exploration in the future.</p>

<p>The performance of the trained decision tree is acceptable, and higher than the baseline logistic regression and even the XGboost model.</p>

<p><strong>In conclusion</strong>, we will choose the decision tree as our best model for two reasons. First, the generalization of the decision tree still maintain good performance in both regular and playoffs game (ROC = 0.75). Seconds, the training and inference time of the decision tree is faster than the XGBoost.</p>

<p>The plot curve of ROC/AUC, Goal rate vs probability percentile, Cumulative proportion of goals vs probability percentile, and Reliability curve of the playoff games.
<img src="/Images/evaluation/playoff_evaluation.png" alt="" /></p>]]></content><author><name></name></author><category term="Data" /><category term="science" /><category term="project" /><summary type="html"><![CDATA[Table of content: 1. Feature Engineering 1 2. Baseline Model 2.1. Unveiling the Accuracy Paradox 2.2. Evaluating Baselines 3. Feature Engineering 2 3.1. Add Features 3.2. Add Json File 4. Advanced Model 5. Best Shot Model 5.1. Data Pre-processing 5.1.1. Add Feature 5.1.2. Feature Selection - Correlation 5.1.3. Feature Selection - Mutual Information 5.1.4. Balance Dataset 5.2. Machine Learning Model Grid Search 5.3. Log the Models to the Experiments on Comet.ml 6. Evaluation 6.1. Evaluate on Regular Season 6.2. Evaluate on Playoff Game]]></summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2023/10/04/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2023-10-04T15:25:05-04:00</published><updated>2023-10-04T15:25:05-04:00</updated><id>http://localhost:4000/jekyll/update/2023/10/04/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2023/10/04/welcome-to-jekyll.html"><![CDATA[<p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>Jekyll requires blog post files to be named according to the following format:</p>

<p><code class="language-plaintext highlighter-rouge">YEAR-MONTH-DAY-title.MARKUP</code></p>

<p>Where <code class="language-plaintext highlighter-rouge">YEAR</code> is a four-digit number, <code class="language-plaintext highlighter-rouge">MONTH</code> and <code class="language-plaintext highlighter-rouge">DAY</code> are both two-digit numbers, and <code class="language-plaintext highlighter-rouge">MARKUP</code> is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></figure>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry><entry><title type="html">Milestone 1</title><link href="http://localhost:4000/data/science/project/2023/10/04/milestone-1.html" rel="alternate" type="text/html" title="Milestone 1" /><published>2023-10-04T15:25:05-04:00</published><updated>2023-10-04T15:25:05-04:00</updated><id>http://localhost:4000/data/science/project/2023/10/04/milestone-1</id><content type="html" xml:base="http://localhost:4000/data/science/project/2023/10/04/milestone-1.html"><![CDATA[<h1 id="table-of-content">Table of content:</h1>

<p><a href="#1-download-nhl-play-by-play-data-with-python">1. Download NHL Play-by-Play Data with Python</a></p>

<p><a href="#2-guide-to-interactive-nhl-game-data-panel">2. Guide to Interactive NHL Game Data Panel</a></p>

<p><a href="#3-tidy-data">3. Tidy Data</a></p>

<p><a href="#4-simple-visualizations">4. Simple Visualizations</a></p>

<p><a href="#5-advanced-visualization">5. Advanced visualization</a></p>

<hr />
<h2 id="1-download-nhl-play-by-play-data-with-python">1. Download NHL Play-by-Play Data with Python</h2>

<p>If you’re looking to download NHL play-by-play data for analysis or other purposes, you’re in the right place :)). This guide will walk you through the <code class="language-plaintext highlighter-rouge">Crawler</code> class, a Python script that can help you scrape and store NHL game data, including play-by-play data.</p>

<h3 id="11-prerequisites">1.1. Prerequisites</h3>

<p>Before you get started, ensure you have the following prerequisites:</p>
<ol>
  <li>Python installed on your system.</li>
  <li>Libraries: <code class="language-plaintext highlighter-rouge">requests</code> and <code class="language-plaintext highlighter-rouge">pathlib</code>. You can install these with pip:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install requests
</code></pre></div>    </div>
  </li>
</ol>

<h3 id="12-getting-started">1.2. Getting Started</h3>
<p>The Python script, <code class="language-plaintext highlighter-rouge">crawler.py</code>, will help you download NHL play-by-play data. Here’s how you can use it:</p>
<ol>
  <li>Download the script from the provided location and save it to your local machine.</li>
  <li>Open a command prompt or terminal window and navigate to the directory where you saved the script.</li>
  <li>Run the script using the following command:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python crawler.py
</code></pre></div>    </div>
  </li>
  <li>The script will start collecting NHL play-by-play data for the specified range of seasons. You can adjust the start and end seasons by modifying the <code class="language-plaintext highlighter-rouge">start_season</code> and <code class="language-plaintext highlighter-rouge">end_season</code> values in the script.</li>
  <li>The collected data will be stored in a directory named <code class="language-plaintext highlighter-rouge">Dataset</code> within the script’s directory.</li>
</ol>

<h3 id="13-explanation-of-the-python-script">1.3. Explanation of the Python Script</h3>

<p>Let’s break down the key parts of the Python script:</p>

<h4 id="131-importing-necessary-modules">1.3.1. Importing Necessary Modules</h4>

<p>The script starts by importing the required Python modules, including <code class="language-plaintext highlighter-rouge">Path</code> for file manipulation, <code class="language-plaintext highlighter-rouge">requests</code> for web requests, and <code class="language-plaintext highlighter-rouge">json</code> for handling JSON data.</p>

<h4 id="132-class-definition-crawler">1.3.2. Class Definition: <code class="language-plaintext highlighter-rouge">Crawler</code></h4>

<p>The script defines a Python class named <code class="language-plaintext highlighter-rouge">Crawler</code>. This class encapsulates the functionality to fetch and store NHL game data. The script provides various methods within this class to handle data retrieval, storage, and access.</p>

<h4 id="133-data-storage-and-initialization">1.3.3. Data Storage and Initialization</h4>

<p>The class initializes instance variables such as the base URL for the NHL data API, paths for data storage, dictionaries for game types, and data storage containers.</p>

<h4 id="134-generating-game-ids">1.3.4. Generating Game IDs</h4>

<p>The class provides methods to generate game IDs for regular season and playoff games, which are used to fetch game data from the NHL API.</p>

<h4 id="135-data-collection">1.3.5. Data Collection</h4>

<p>The <code class="language-plaintext highlighter-rouge">get_url</code> method constructs the full URL for fetching game data, and the <code class="language-plaintext highlighter-rouge">get_game_data</code> method fetches data from the NHL API using the constructed URL. The script checks the response status code to ensure a successful request.</p>

<p>Also, the script defines functions to retrieve data for regular season and playoff games. These functions use the generated game IDs and fetch the corresponding game data.</p>

<p>Finally, the <code class="language-plaintext highlighter-rouge">get_total_data</code> method collects data for a specified range of seasons, storing it in the <code class="language-plaintext highlighter-rouge">self.data</code> dictionary.</p>

<h4 id="136-data-storage">1.3.6. Data Storage</h4>

<p>The <code class="language-plaintext highlighter-rouge">write_data</code> method writes the collected game data to JSON files in the <code class="language-plaintext highlighter-rouge">Dataset</code> directory, organizing them by season and game type.</p>

<h4 id="137-dataset-information">1.3.7. Dataset Information</h4>

<p>The <code class="language-plaintext highlighter-rouge">write_dataset_info</code> method writes information about the dataset, including the start and end seasons, to a JSON file.</p>

<h4 id="138-data-retrieval">1.3.8. Data Retrieval</h4>

<p>The <code class="language-plaintext highlighter-rouge">read_data</code> method reads all the collected data from JSON files and organizes it into a structured dictionary.</p>

<p>The <code class="language-plaintext highlighter-rouge">read_data_by_game_id</code> method allows you to retrieve data for a specific game by providing its game ID.</p>

<h3 id="14-example-usage">1.4. Example Usage</h3>

<p>Here’s an example of how to use the script to collect NHL play-by-play data:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python crawler.py
</code></pre></div></div>

<p>This command will collect NHL play-by-play data for the specified range of seasons and store it in the “Dataset” directory. You can access the collected data and retrieve specific game data using the provided methods within the <code class="language-plaintext highlighter-rouge">Crawler</code> class.</p>

<p>With this script, you can easily download NHL play-by-play data and perform various analyses or build applications based on the obtained data. Enjoy exploring and working with NHL game data!</p>

<hr />
<h2 id="2-guide-to-interactive-nhl-game-data-panel">2. Guide to Interactive NHL Game Data Panel</h2>

<p>In this guide, we’ll explore how to use an interactive Python script to access and visualize NHL game data. The script includes graphical user interface elements to select, view, and plot game from NHL data.</p>

<!-- 
### 2.1 Using the Interactive Panel

The interactive panel allows you to explore NHL game data in a user-friendly manner. Let's break down how to use each part of the code:

#### Importing Necessary Libraries and Modules

This block imports essential Python modules, such as IPython widgets for creating the GUI, Matplotlib for data visualization, Pillow for image manipulation, and NumPy for data manipulation. It also imports the `Crawler` class from an external module.

#### Creating an Instance of the 'Crawler' Class

In this block, an instance of the `Crawler` class is created. The `Crawler` class handles the retrieval of NHL game data.

#### Defining the `Panel` Class

The `Panel` class is introduced to manage the graphical user interface for data selection and display. The following functionalities are implemented:

- **Season Selection:** You can select your desired season among all available seasons automatically specified by the `crawler`. The season is also updated based on the entered game ID.

- **Game Type Selection:** You can select your desired game type between regular and playoff games. The game type is also updated based on the entered game ID.

- **Game ID Selection:** The game ID is adjusted based on the selected season and game type. The only thing you may want to change is the game ID (last 4 digits).

- **'Go' Button:** This button fetches and displays selected game data, allowing you to explore the data interactively.

- **'Show' Button:** This button displays the selected data in a user-friendly format.

- **'Reset' Button:** This button resets the control panel to its default values.

- **Data Selection:** It enables you to select data categories and drill down into the information.


#### Creating an Instance of the `Panel` Class

In this block, an instance of the `Panel` class is created, which initiates the interactive panel in your Jupyter Notebook environment. 

### Example Usage

Open a Jupyter Notebook environment.

- Copy and paste the provided code blocks into separate cells in your notebook.

- Run each code block sequentially.

- Once you run the last code block, the interactive panel will be displayed in your notebook. -->

<ol>
  <li>
    <p>You can start by selecting the season and game type, and then click the ‘Go’ button to fetch and display NHL game data.</p>
  </li>
  <li>
    <p>Use the ‘Show’ button to view the selected data in a readable format. This is an example of debugging tool visualization:
<img src="/Images/Interactive_debugging/interactive_debugging_tool_visualization.png" alt="" width="100%" /></p>
  </li>
  <li>
    <p>You can also reset the panel using the ‘Reset’ button to start fresh.</p>
  </li>
  <li>
    <p>The panel allows you to explore and visualize data for specific NHL games.</p>
  </li>
</ol>

<p>The interactive panel is a powerful tool for accessing and visualizing NHL game data with ease. Enjoy exploring and analyzing NHL game data interactively!</p>

<hr />
<h2 id="3-tidy-data">3. Tidy Data</h2>

<h3 id="31-dataframe-overview">3.1. Dataframe overview</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dataFrame.head(10)
</code></pre></div></div>
<p><img src="/Images/Tidy_data/dataFrame_head.png" alt="" width="100%" /></p>

<h3 id="32-actual-strength-of-players">3.2. Actual strength of players</h3>

<p>One possible way to find the actual strength of the players in each event of a game is to start with 5 on 5 and then adjust the number of players according to the penalties that occur. For example, if a penalty leads to an ejection of a player, the number of players for that team will decrease by one for the duration of the penalty. If an event happens during that time, the actual strength of the players will be the number of players for each team after accounting for the penalties. Similarly, if another penalty occurs while a previous penalty is still in effect, the number of players will decrease accordingly.</p>

<h3 id="33-additional-features">3.3. Additional features</h3>

<p><strong>Attacking side</strong>: We can find the home team from the following sequence of dictionaries: linescore -&gt; teams -&gt; home -&gt; team -&gt; name  We also have the period number for each event. Moreover, we can find all the periods in liveData -&gt; linescore -&gt; periods. Now, to find the attacking side for a specific event, we have to find the related period and check the rink side for the home team and the away team. Since we already know whether the home team or the away team was responsible for the event, we can find the attacking side based on the rink side.</p>

<p><strong>Shot distance</strong>: We can find the distance of a shot based on the coordinates of the shot and the coordinates of the net. The coordinates of the net depend on the attacking side, which we have it already.</p>

<p><strong>Number of players</strong>: To find the actual strength of the players in each event of a game, we have to keep track of the number of players for each team. As we explained in the “Actual strength of players” section, we can start with 5 on 5 and then adjust the number of players according to the penalties that occur. If a penalty leads to an ejection of a player, we decrease the number of players for that team by one for the duration of the penalty. When an event happens, we can compare the time of the event and the time of the last penalty and see if the number of players should be changed accordingly.</p>

<p><strong>Shot angel</strong>: We can find the angle of the shot by dividing the shot distance by the y-coordinate, which gives us the sine of the shot angle. Then, we can find the angle by taking the inverse sine of the result.</p>

<hr />
<h2 id="4-simple-visualizations">4. Simple Visualizations</h2>

<h3 id="41-comparing-shot-types">4.1. Comparing Shot Types</h3>

<p>I chose the 2016 season (including both the regular season and playoffs) to produce a figure that compares shot types across all teams. In analyzing the data, it becomes clear that the most dangerous type of shot is the <strong>“deflected shot”</strong>, with the highest goal percentage of <strong>19.8%</strong>. This suggests that deflected shots have a significantly higher chance of resulting in a goal compared to other shot types.</p>

<p>On the other hand, the most common type of shot is the <strong>“wrist shot”</strong>, as indicated by the highest bar in the histogram. The reason I chose this figure is that it provides a straightforward visual representation of the shot and goal counts for each shot type, allowing us to easily compare their quantities and ratios. It’s a valuable tool for understanding which shot types are both frequent and effective in scoring goals.</p>

<p><img src="/Images/Simple_Visualizations/Q5-1_shot_type_histogram.png" alt="" /></p>

<h3 id="42-relationship-between-shot-distance-and-goal-chance">4.2. Relationship between Shot Distance and Goal Chance</h3>

<p>In ice hockey matches, it is generally observed that the <strong>closer the shot distance to the goal, the higher the probability of scoring</strong>. This is because when a player is closer to the goal, the goalkeeper’s defensive range is reduced, increasing the chances of successfully putting the puck into the net. It is clear that the scoring probability is significantly higher for shot distances less than 70 feet when compared to shot distances greater than 70 feet. This trend remained consistent across the years 2018, 2019, and 2020. I opted for a line plot graph as it provides a direct visualization of how the likelihood of scoring changes with varying shot distances.</p>

<p><img src="/Images/Simple_Visualizations/Q5-2_shot_distance_vs_goal_chance_2018.png" alt="" />
<img src="/Images/Simple_Visualizations/Q5-2_shot_distance_vs_goal_chance_2019.png" alt="" />
<img src="/Images/Simple_Visualizations/Q5-2_shot_distance_vs_goal_chance_2020.png" alt="" /></p>

<h3 id="43-goal-percentage-by-shot-distance-and-type">4.3. Goal Percentage by Shot Distance and Type</h3>

<p>In this analysis, I utilized data from the year 2016, including both regular season and playoff games. The figure reveals that there isn’t a single shot type that stands out as the most dangerous across all shot distances. Instead, each shot type has its own optimal goal-scoring range.</p>

<p>It’s evident that when the shot distance is less than 10 feet, the “wrap-around” shot type appears to be the most dangerous, as it boasts the highest average goal-scoring probability in that range. In the 10 to 20 feet distance range, “Tip-in” or “Deflected” shots are preferable choices. When the shot distance extends to the 20 to 40 feet range, “Snap Shot” becomes a more effective option. For distances greater than 40 feet but less than 70 feet, “Slap Shot” appears to be a favorable choice. However, when the shot distance exceeds 70 feet, the goal-scoring probability for all shot types decreases significantly.</p>

<p><img src="/Images/Simple_Visualizations/Q5-3_distance_and_type_vs_goal_for_2016-2017.png" alt="" /></p>

<hr />
<h2 id="5-advanced-visualization">5. Advanced visualization</h2>

<h3 id="51-export-html-plot">5.1. Export html plot</h3>

<p>The shot map visualization are stored <a href="/Images/Advanced_visualization/shot_map_visualization.html">here</a></p>

<h3 id="52-discusss-from-shot-map">5.2. Discusss from shot map</h3>
<p>The main idea here is to measure the frequency of shots from specific positions for each team compared to the league average. This measure helps highlight areas where a team may be particularly strong or weak compared to the average league.</p>

<p>For example, if Team A has a higher shot rate in front of the net, it suggests that Team A is likely to take shots at close range compared to the average league.</p>

<h3 id="53-discuss-about-the-team-colorado-avalanche">5.3. Discuss about the team <em>Colorado Avalanche</em></h3>
<p>In season 2016-2017, the Colorado Avalanche had dark blue in front of the net, which means that this team took fewer shots compared to the average league. We can assume that the forwards of this team are bad at the shot. As a result, this team final at the lowest ranking of the league.</p>

<p><img src="/Images/Advanced_visualization/2016/Colorado%20Avalanche.jpg" alt="" title="Shot map of Colorado Avalanche in season 2016-2017" width="500px" /></p>

<p>In season 2020-2021, the Colorado Avalanche have a dark red in the middle of the offensive zone, which mean that this team takes a lot of shot. In other words, the forwards of this team are good at controlling the match and shot. Finally, this team takes the highest position in the standings.</p>

<p><img src="/Images/Advanced_visualization/2020/Colorado%20Avalanche.jpg" alt="" title="Shot map of Colorado Avalanche in season 2020-2021" width="500px" /></p>

<p>The analysis and final results make sense.</p>

<h3 id="54-comparision-between-buffalo-sabres-and-tampa-bay-lightning">5.4. Comparision between <em>Buffalo Sabres</em> and <em>Tampa Bay Lightning</em></h3>
<p>Buffalo Sabres:</p>
<ul>
  <li>
    <p>From the 2018-2020 seasons, this team had a dark blue area in front of the net. This means that this team can not approach the opponent’s goal and take a shot.</p>
  </li>
  <li>
    <p>Although the Buffalo Sabres have some dark red area in the map (in the year 2018-2019), it is far from the net. It is a long-range shot, which is not really an effective strategy.</p>
  </li>
</ul>

<p><img src="/Images/Advanced_visualization/2018/Buffalo%20Sabres.jpg" alt="" width="500px" /></p>

<p><img src="/Images/Advanced_visualization/2019/Buffalo%20Sabres.jpg" alt="" width="500px" /></p>

<p><img src="/Images/Advanced_visualization/2020/Buffalo%20Sabres.jpg" alt="" width="500px" /></p>

<p>Tampa Bay Lightning:</p>

<ul>
  <li>This team had a dark red area in front of the net during 2018-2020. This means that this team control the match and take a lot of shot to the opponent’s net.</li>
</ul>

<p><img src="/Images/Advanced_visualization/2018/Tampa%20Bay%20Lightning.jpg" alt="" width="500px" /></p>

<p><img src="/Images/Advanced_visualization/2019/Tampa%20Bay%20Lightning.jpg" alt="" width="500px" /></p>

<p><img src="/Images/Advanced_visualization/2020/Tampa%20Bay%20Lightning.jpg" alt="" width="500px" /></p>

<p>In general, the Tampa Bay Lightning team had a good attacking strategy, which is one of the key points to make this team success during three consecutive seasons.</p>]]></content><author><name></name></author><category term="Data" /><category term="science" /><category term="project" /><summary type="html"><![CDATA[Table of content:]]></summary></entry></feed>